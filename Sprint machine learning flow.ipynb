{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python369jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.6.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn import linear_model, tree, ensemble\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy = 'median')"
   ]
  },
  {
   "source": [
    "# Sprint machine learning flow\n",
    "## Name: Nguyen Anh Hoang Phuc"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Problem 1 Cross Validation\n",
    "In the pre-learning period, the verification data was divided first, and the index value was calculated for that, and verification was performed. (Holdout method) However, the accuracy varies depending on the division method; in practice Cross Validation. This is a method of performing splitting multiple times and performing learning and verification for each. KFold class is provided in scikit-learn for splitting multiple times.\n",
    "\n",
    "Create and execute code that Validation baseline model created in the pre-learning period assignment\n",
    "\n",
    "sklearn.model_selection.KFold â€” scikit-learn 0.21.3 documentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In the pre-learning period, the verification data was divided first, and the index value was calculated for that, and verification was performed. (Holdout method) However, the accuracy varies depending on the division method; in practice Cross Validation. This is a method of performing splitting multiple times and performing learning and verification for each. KFold class is provided in scikit-learn for splitting multiple times.\n",
    "\n",
    "Create and execute code that Validation baseline model created in the pre-learning period assignment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('application_train.csv')\n",
    "train_data.dropna(axis=0, subset=['TARGET'], inplace=True)\n",
    "y = train_data.TARGET # Target variable \n",
    "train_data.drop(['TARGET'], axis=1, inplace=True) # Removing target variable from training data\n",
    "COLUMNS = list(train_data.columns)\n",
    "# get only existing data with no missing values\n",
    "train_data = train_data[train_data.columns[~train_data.isnull().all()]]"
   ]
  },
  {
   "source": [
    "### Test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(48744, 121)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "test_data = pd.read_csv('application_test.csv')\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(48744, 105)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "COLUMNS = list(test_data.columns)\n",
    "# get only existing data with no missing values\n",
    "test_data = test_data[test_data.columns[~test_data.isnull().all()]]\n",
    "test_data = test_data.select_dtypes('number')\n",
    "test_data = test_data.fillna(test_data.median()).clip(-1e11,1e11)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   SK_ID_CURR  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0      100001             0          135000.0    568800.0      20560.5   \n",
       "1      100005             0           99000.0    222768.0      17370.0   \n",
       "2      100013             0          202500.0    663264.0      69777.0   \n",
       "3      100028             2          315000.0   1575000.0      49018.5   \n",
       "4      100038             1          180000.0    625500.0      32067.0   \n",
       "\n",
       "   AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
       "0         450000.0                    0.018850      -19241          -2329   \n",
       "1         180000.0                    0.035792      -18064          -4469   \n",
       "2         630000.0                    0.019101      -20038          -4458   \n",
       "3        1575000.0                    0.026392      -13976          -1866   \n",
       "4         625500.0                    0.010032      -13040          -2191   \n",
       "\n",
       "   DAYS_REGISTRATION  ...  FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  \\\n",
       "0            -5170.0  ...                 0                 0   \n",
       "1            -9118.0  ...                 0                 0   \n",
       "2            -2175.0  ...                 0                 0   \n",
       "3            -2000.0  ...                 0                 0   \n",
       "4            -4000.0  ...                 0                 0   \n",
       "\n",
       "   FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "0                 0                 0                         0.0   \n",
       "1                 0                 0                         0.0   \n",
       "2                 0                 0                         0.0   \n",
       "3                 0                 0                         0.0   \n",
       "4                 0                 0                         0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "0                        0.0                         0.0   \n",
       "1                        0.0                         0.0   \n",
       "2                        0.0                         0.0   \n",
       "3                        0.0                         0.0   \n",
       "4                        0.0                         0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        1.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                         0.0  \n",
       "1                         3.0  \n",
       "2                         4.0  \n",
       "3                         3.0  \n",
       "4                         2.0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SK_ID_CURR</th>\n      <th>CNT_CHILDREN</th>\n      <th>AMT_INCOME_TOTAL</th>\n      <th>AMT_CREDIT</th>\n      <th>AMT_ANNUITY</th>\n      <th>AMT_GOODS_PRICE</th>\n      <th>REGION_POPULATION_RELATIVE</th>\n      <th>DAYS_BIRTH</th>\n      <th>DAYS_EMPLOYED</th>\n      <th>DAYS_REGISTRATION</th>\n      <th>...</th>\n      <th>FLAG_DOCUMENT_18</th>\n      <th>FLAG_DOCUMENT_19</th>\n      <th>FLAG_DOCUMENT_20</th>\n      <th>FLAG_DOCUMENT_21</th>\n      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100001</td>\n      <td>0</td>\n      <td>135000.0</td>\n      <td>568800.0</td>\n      <td>20560.5</td>\n      <td>450000.0</td>\n      <td>0.018850</td>\n      <td>-19241</td>\n      <td>-2329</td>\n      <td>-5170.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100005</td>\n      <td>0</td>\n      <td>99000.0</td>\n      <td>222768.0</td>\n      <td>17370.0</td>\n      <td>180000.0</td>\n      <td>0.035792</td>\n      <td>-18064</td>\n      <td>-4469</td>\n      <td>-9118.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100013</td>\n      <td>0</td>\n      <td>202500.0</td>\n      <td>663264.0</td>\n      <td>69777.0</td>\n      <td>630000.0</td>\n      <td>0.019101</td>\n      <td>-20038</td>\n      <td>-4458</td>\n      <td>-2175.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100028</td>\n      <td>2</td>\n      <td>315000.0</td>\n      <td>1575000.0</td>\n      <td>49018.5</td>\n      <td>1575000.0</td>\n      <td>0.026392</td>\n      <td>-13976</td>\n      <td>-1866</td>\n      <td>-2000.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100038</td>\n      <td>1</td>\n      <td>180000.0</td>\n      <td>625500.0</td>\n      <td>32067.0</td>\n      <td>625500.0</td>\n      <td>0.010032</td>\n      <td>-13040</td>\n      <td>-2191</td>\n      <td>-4000.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 105 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "source": [
    "### Select numeric columns only\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of input data: (307511, 105) and shape of target variable: (307511,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   SK_ID_CURR  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0      100002             0          202500.0    406597.5      24700.5   \n",
       "1      100003             0          270000.0   1293502.5      35698.5   \n",
       "2      100004             0           67500.0    135000.0       6750.0   \n",
       "3      100006             0          135000.0    312682.5      29686.5   \n",
       "4      100007             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
       "0         351000.0                    0.018801       -9461           -637   \n",
       "1        1129500.0                    0.003541      -16765          -1188   \n",
       "2         135000.0                    0.010032      -19046           -225   \n",
       "3         297000.0                    0.008019      -19005          -3039   \n",
       "4         513000.0                    0.028663      -19932          -3038   \n",
       "\n",
       "   DAYS_REGISTRATION  ...  FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  \\\n",
       "0            -3648.0  ...                 0                 0   \n",
       "1            -1186.0  ...                 0                 0   \n",
       "2            -4260.0  ...                 0                 0   \n",
       "3            -9833.0  ...                 0                 0   \n",
       "4            -4311.0  ...                 0                 0   \n",
       "\n",
       "   FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "0                 0                 0                         0.0   \n",
       "1                 0                 0                         0.0   \n",
       "2                 0                 0                         0.0   \n",
       "3                 0                 0                         0.0   \n",
       "4                 0                 0                         0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "0                        0.0                         0.0   \n",
       "1                        0.0                         0.0   \n",
       "2                        0.0                         0.0   \n",
       "3                        0.0                         0.0   \n",
       "4                        0.0                         0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                         1.0  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         1.0  \n",
       "4                         0.0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SK_ID_CURR</th>\n      <th>CNT_CHILDREN</th>\n      <th>AMT_INCOME_TOTAL</th>\n      <th>AMT_CREDIT</th>\n      <th>AMT_ANNUITY</th>\n      <th>AMT_GOODS_PRICE</th>\n      <th>REGION_POPULATION_RELATIVE</th>\n      <th>DAYS_BIRTH</th>\n      <th>DAYS_EMPLOYED</th>\n      <th>DAYS_REGISTRATION</th>\n      <th>...</th>\n      <th>FLAG_DOCUMENT_18</th>\n      <th>FLAG_DOCUMENT_19</th>\n      <th>FLAG_DOCUMENT_20</th>\n      <th>FLAG_DOCUMENT_21</th>\n      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100002</td>\n      <td>0</td>\n      <td>202500.0</td>\n      <td>406597.5</td>\n      <td>24700.5</td>\n      <td>351000.0</td>\n      <td>0.018801</td>\n      <td>-9461</td>\n      <td>-637</td>\n      <td>-3648.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100003</td>\n      <td>0</td>\n      <td>270000.0</td>\n      <td>1293502.5</td>\n      <td>35698.5</td>\n      <td>1129500.0</td>\n      <td>0.003541</td>\n      <td>-16765</td>\n      <td>-1188</td>\n      <td>-1186.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100004</td>\n      <td>0</td>\n      <td>67500.0</td>\n      <td>135000.0</td>\n      <td>6750.0</td>\n      <td>135000.0</td>\n      <td>0.010032</td>\n      <td>-19046</td>\n      <td>-225</td>\n      <td>-4260.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100006</td>\n      <td>0</td>\n      <td>135000.0</td>\n      <td>312682.5</td>\n      <td>29686.5</td>\n      <td>297000.0</td>\n      <td>0.008019</td>\n      <td>-19005</td>\n      <td>-3039</td>\n      <td>-9833.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100007</td>\n      <td>0</td>\n      <td>121500.0</td>\n      <td>513000.0</td>\n      <td>21865.5</td>\n      <td>513000.0</td>\n      <td>0.028663</td>\n      <td>-19932</td>\n      <td>-3038</td>\n      <td>-4311.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 105 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Select numeric columns only\n",
    "# numeric_cols = [cname for cname in train_data.columns if train_data[cname].dtypes in ['int64']]\n",
    "# X = train_data[numeric_cols].copy()\n",
    "train_data = train_data.select_dtypes('number')\n",
    "X = train_data\n",
    "X = X.fillna(X.median()).clip(-1e11,1e11)\n",
    "\n",
    "print(\"Shape of input data: {} and shape of target variable: {}\".format(X.shape, y.shape))\n",
    "\n",
    "X.head() # Show first 5 training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the target back in\n",
    "train_data['TARGET'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fold:1, Train set: 246008, Test set:61503\nFold:2, Train set: 246009, Test set:61502\nFold:3, Train set: 246009, Test set:61502\nFold:4, Train set: 246009, Test set:61502\nFold:5, Train set: 246009, Test set:61502\n"
     ]
    }
   ],
   "source": [
    "# Lets split the data into 5 folds.  \n",
    "# We will use this 'kf'(KFold splitting stratergy) object as input to cross_val_score() method\n",
    "kf =KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cnt = 1\n",
    "# split()  method generate indices to split data into training and test set.\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print(f'Fold:{cnt}, Train set: {len(train_index)}, Test set:{len(test_index)}')\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(score):\n",
    "    rmse = np.sqrt(-score)\n",
    "    print(f'rmse= {\"{:.2f}\".format(rmse)}')"
   ]
  },
  {
   "source": [
    "### Using Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores for each fold: [-0.06977236 -0.06965837 -0.07142571 -0.06929756 -0.06988258]\nrmse= 0.26\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(linear_model.LinearRegression(), X, y, cv= kf, scoring=\"neg_mean_squared_error\")\n",
    "print(f'Scores for each fold: {score}')\n",
    "rmse(score.mean())"
   ]
  },
  {
   "source": [
    "### Using Decision Tree Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores for each fold: [-0.15031787 -0.14885695 -0.15072681 -0.15032031 -0.14740984]\nrmse= 0.39\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(tree.DecisionTreeRegressor(random_state= 42), X, y, cv=kf, scoring=\"neg_mean_squared_error\")\n",
    "print(f'Scores for each fold: {score}')\n",
    "rmse(score.mean())"
   ]
  },
  {
   "source": [
    "## Problem 2 Grid search\n",
    "So far, I haven't touched on the classifier parameters and used the default settings. Details of the parameters will be learned in future sprints. As a prerequisite for machine learning, it is necessary to select the optimum parameters according to the situation. Searching for the optimum parameters is called parameter tuning. A simple way to automate parameter tuning to some extent is grid search.\n",
    "\n",
    "Please use Scikit-learn's GridSearchCV to create the code for grid search. Then do some parameter tuning on the baseline model. Please refer to the official documentation of the method used to determine which parameters to tune.\n",
    "\n",
    "sklearn.model_selection.GridSearchCV â€” scikit-learn 0.21.3 documentation\n",
    "\n",
    "To the GridSearchCV class, give the model, the search range, and the number of divisions for cross Validation as arguments. You don't need to use KFold class if you want to use it as it also includes cross Validation functionality."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Grid\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [3],\n",
    "    'max_features': [2],\n",
    "    'min_samples_leaf': [3],\n",
    "    'min_samples_split': [8, 10],\n",
    "    'n_estimators': [100, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=RandomForestClassifier(max_depth=2, random_state=0),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [3],\n",
       "                         'max_features': [2], 'min_samples_leaf': [3],\n",
       "                         'min_samples_split': [8, 10],\n",
       "                         'n_estimators': [100, 200]},\n",
       "             verbose=2)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 2, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "#### The Best Parameter:\n",
    "I have run GridSearch on many values and here is the best parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 3,\n",
       " 'max_features': 2,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 100}"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "source": [
    "## Problem 3: Survey from Kaggle Notebooks\n",
    "Discover and list various ideas from Kaggle's Notebooks.\n",
    "\n",
    "Some ideas I have found on Kaggle:\n",
    "<li> Use advance models: Random Forest, Gradient Boosting\n",
    "<li> Apply advance Feature Engineering: use domain knowledge features(credit_income_percent,annuity_income_percent,credit_term,days_emplyed_percent)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Problem 4: Creating a model with high generalization performance\n",
    "\n",
    "Please combine the idea found in Problem 3 and your own idea to create a model with high generalization performance.\n",
    "\n",
    "\n",
    "As a process, please summarize in a table what you did and how much the cross Validation results changed."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Domain Knowledge Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_train = train_data.copy()\n",
    "domain_test = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_train['CREDIT_INCOME_PERCENT'] = domain_train['AMT_CREDIT'] / domain_train['AMT_INCOME_TOTAL']\n",
    "domain_train['ANNUITY_INCOME_PERCENT'] = domain_train['AMT_ANNUITY'] / domain_train['AMT_INCOME_TOTAL']\n",
    "domain_train['CREDIT_TERM'] = domain_train['AMT_ANNUITY'] / domain_train['AMT_CREDIT']\n",
    "domain_train['DAYS_EMPLOYED_PERCENT'] = domain_train['DAYS_EMPLOYED'] / domain_train['DAYS_BIRTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_test['CREDIT_INCOME_PERCENT'] = domain_test['AMT_CREDIT'] / domain_test['AMT_INCOME_TOTAL']\n",
    "domain_test['ANNUITY_INCOME_PERCENT'] = domain_test['AMT_ANNUITY'] / domain_test['AMT_INCOME_TOTAL']\n",
    "domain_test['CREDIT_TERM'] = domain_test['AMT_ANNUITY'] / domain_test['AMT_CREDIT']\n",
    "domain_test['DAYS_EMPLOYED_PERCENT'] = domain_test['DAYS_EMPLOYED'] / domain_test['DAYS_BIRTH']"
   ]
  },
  {
   "source": [
    "### Training with Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "rf.fit(X, y)"
   ]
  },
  {
   "source": [
    "### Predict using Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(48744,)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "rf_pred = rf.predict_proba(test_data)[:,1]\n",
    "rf_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   SK_ID_CURR    TARGET\n",
       "0      100001  0.091578\n",
       "1      100005  0.084732\n",
       "2      100013  0.068804\n",
       "3      100028  0.064782\n",
       "4      100038  0.090223"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SK_ID_CURR</th>\n      <th>TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100001</td>\n      <td>0.091578</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100005</td>\n      <td>0.084732</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100013</td>\n      <td>0.068804</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100028</td>\n      <td>0.064782</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100038</td>\n      <td>0.090223</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "submit = test_data[['SK_ID_CURR']]\n",
    "submit['TARGET'] = rf_pred\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to CSV\n",
    "submit.to_csv('rf_prediction.csv', index = False)"
   ]
  },
  {
   "source": [
    "### Predict using Random Forest for Domain Knowledge Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(307511, 106)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   28.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "train_domain = domain_train.drop(columns = 'TARGET')\n",
    "\n",
    "domain_features_names = list(train_domain.columns)\n",
    "\n",
    "# Impute the domainnomial features\n",
    "\n",
    "domain_features = imputer.fit_transform(train_domain)\n",
    "domain_features_test = imputer.transform(domain_test)\n",
    "\n",
    "# Scale the domainnomial features\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "\n",
    "domain_features = scaler.fit_transform(domain_features)\n",
    "domain_features_test = scaler.transform(domain_features_test)\n",
    "\n",
    "random_forest_domain = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)\n",
    "\n",
    "# Train on the training data\n",
    "random_forest_domain.fit(domain_features, y)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importance_values_domain = random_forest_domain.feature_importances_\n",
    "feature_importances_domain = pd.DataFrame({'feature': domain_features_names, 'importance': feature_importance_values_domain})\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = random_forest_domain.predict_proba(domain_features_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(48744,)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        SK_ID_CURR  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0           100002             0          202500.0    406597.5      24700.5   \n",
       "1           100003             0          270000.0   1293502.5      35698.5   \n",
       "2           100004             0           67500.0    135000.0       6750.0   \n",
       "3           100006             0          135000.0    312682.5      29686.5   \n",
       "4           100007             0          121500.0    513000.0      21865.5   \n",
       "...            ...           ...               ...         ...          ...   \n",
       "307506      456251             0          157500.0    254700.0      27558.0   \n",
       "307507      456252             0           72000.0    269550.0      12001.5   \n",
       "307508      456253             0          153000.0    677664.0      29979.0   \n",
       "307509      456254             0          171000.0    370107.0      20205.0   \n",
       "307510      456255             0          157500.0    675000.0      49117.5   \n",
       "\n",
       "        AMT_GOODS_PRICE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  \\\n",
       "0              351000.0                    0.018801       -9461   \n",
       "1             1129500.0                    0.003541      -16765   \n",
       "2              135000.0                    0.010032      -19046   \n",
       "3              297000.0                    0.008019      -19005   \n",
       "4              513000.0                    0.028663      -19932   \n",
       "...                 ...                         ...         ...   \n",
       "307506         225000.0                    0.032561       -9327   \n",
       "307507         225000.0                    0.025164      -20775   \n",
       "307508         585000.0                    0.005002      -14966   \n",
       "307509         319500.0                    0.005313      -11961   \n",
       "307510         675000.0                    0.046220      -16856   \n",
       "\n",
       "        DAYS_EMPLOYED  DAYS_REGISTRATION  ...  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                -637            -3648.0  ...                        0.0   \n",
       "1               -1188            -1186.0  ...                        0.0   \n",
       "2                -225            -4260.0  ...                        0.0   \n",
       "3               -3039            -9833.0  ...                        NaN   \n",
       "4               -3038            -4311.0  ...                        0.0   \n",
       "...               ...                ...  ...                        ...   \n",
       "307506           -236            -8456.0  ...                        NaN   \n",
       "307507         365243            -4388.0  ...                        NaN   \n",
       "307508          -7921            -6737.0  ...                        0.0   \n",
       "307509          -4786            -2562.0  ...                        0.0   \n",
       "307510          -1262            -5128.0  ...                        0.0   \n",
       "\n",
       "        AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                              0.0                        0.0   \n",
       "1                              0.0                        0.0   \n",
       "2                              0.0                        0.0   \n",
       "3                              NaN                        NaN   \n",
       "4                              0.0                        0.0   \n",
       "...                            ...                        ...   \n",
       "307506                         NaN                        NaN   \n",
       "307507                         NaN                        NaN   \n",
       "307508                         0.0                        1.0   \n",
       "307509                         0.0                        0.0   \n",
       "307510                         0.0                        2.0   \n",
       "\n",
       "        AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  TARGET  \\\n",
       "0                             0.0                         1.0       1   \n",
       "1                             0.0                         0.0       0   \n",
       "2                             0.0                         0.0       0   \n",
       "3                             NaN                         NaN       0   \n",
       "4                             0.0                         0.0       0   \n",
       "...                           ...                         ...     ...   \n",
       "307506                        NaN                         NaN       0   \n",
       "307507                        NaN                         NaN       0   \n",
       "307508                        0.0                         1.0       0   \n",
       "307509                        0.0                         0.0       1   \n",
       "307510                        0.0                         1.0       0   \n",
       "\n",
       "        CREDIT_INCOME_PERCENT  ANNUITY_INCOME_PERCENT  CREDIT_TERM  \\\n",
       "0                    2.007889                0.121978     0.060749   \n",
       "1                    4.790750                0.132217     0.027598   \n",
       "2                    2.000000                0.100000     0.050000   \n",
       "3                    2.316167                0.219900     0.094941   \n",
       "4                    4.222222                0.179963     0.042623   \n",
       "...                       ...                     ...          ...   \n",
       "307506               1.617143                0.174971     0.108198   \n",
       "307507               3.743750                0.166687     0.044524   \n",
       "307508               4.429176                0.195941     0.044239   \n",
       "307509               2.164368                0.118158     0.054592   \n",
       "307510               4.285714                0.311857     0.072767   \n",
       "\n",
       "        DAYS_EMPLOYED_PERCENT  \n",
       "0                    0.067329  \n",
       "1                    0.070862  \n",
       "2                    0.011814  \n",
       "3                    0.159905  \n",
       "4                    0.152418  \n",
       "...                       ...  \n",
       "307506               0.025303  \n",
       "307507             -17.580890  \n",
       "307508               0.529266  \n",
       "307509               0.400134  \n",
       "307510               0.074869  \n",
       "\n",
       "[307511 rows x 110 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SK_ID_CURR</th>\n      <th>CNT_CHILDREN</th>\n      <th>AMT_INCOME_TOTAL</th>\n      <th>AMT_CREDIT</th>\n      <th>AMT_ANNUITY</th>\n      <th>AMT_GOODS_PRICE</th>\n      <th>REGION_POPULATION_RELATIVE</th>\n      <th>DAYS_BIRTH</th>\n      <th>DAYS_EMPLOYED</th>\n      <th>DAYS_REGISTRATION</th>\n      <th>...</th>\n      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n      <th>TARGET</th>\n      <th>CREDIT_INCOME_PERCENT</th>\n      <th>ANNUITY_INCOME_PERCENT</th>\n      <th>CREDIT_TERM</th>\n      <th>DAYS_EMPLOYED_PERCENT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100002</td>\n      <td>0</td>\n      <td>202500.0</td>\n      <td>406597.5</td>\n      <td>24700.5</td>\n      <td>351000.0</td>\n      <td>0.018801</td>\n      <td>-9461</td>\n      <td>-637</td>\n      <td>-3648.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>2.007889</td>\n      <td>0.121978</td>\n      <td>0.060749</td>\n      <td>0.067329</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100003</td>\n      <td>0</td>\n      <td>270000.0</td>\n      <td>1293502.5</td>\n      <td>35698.5</td>\n      <td>1129500.0</td>\n      <td>0.003541</td>\n      <td>-16765</td>\n      <td>-1188</td>\n      <td>-1186.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4.790750</td>\n      <td>0.132217</td>\n      <td>0.027598</td>\n      <td>0.070862</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100004</td>\n      <td>0</td>\n      <td>67500.0</td>\n      <td>135000.0</td>\n      <td>6750.0</td>\n      <td>135000.0</td>\n      <td>0.010032</td>\n      <td>-19046</td>\n      <td>-225</td>\n      <td>-4260.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>2.000000</td>\n      <td>0.100000</td>\n      <td>0.050000</td>\n      <td>0.011814</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100006</td>\n      <td>0</td>\n      <td>135000.0</td>\n      <td>312682.5</td>\n      <td>29686.5</td>\n      <td>297000.0</td>\n      <td>0.008019</td>\n      <td>-19005</td>\n      <td>-3039</td>\n      <td>-9833.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2.316167</td>\n      <td>0.219900</td>\n      <td>0.094941</td>\n      <td>0.159905</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100007</td>\n      <td>0</td>\n      <td>121500.0</td>\n      <td>513000.0</td>\n      <td>21865.5</td>\n      <td>513000.0</td>\n      <td>0.028663</td>\n      <td>-19932</td>\n      <td>-3038</td>\n      <td>-4311.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4.222222</td>\n      <td>0.179963</td>\n      <td>0.042623</td>\n      <td>0.152418</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>307506</th>\n      <td>456251</td>\n      <td>0</td>\n      <td>157500.0</td>\n      <td>254700.0</td>\n      <td>27558.0</td>\n      <td>225000.0</td>\n      <td>0.032561</td>\n      <td>-9327</td>\n      <td>-236</td>\n      <td>-8456.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1.617143</td>\n      <td>0.174971</td>\n      <td>0.108198</td>\n      <td>0.025303</td>\n    </tr>\n    <tr>\n      <th>307507</th>\n      <td>456252</td>\n      <td>0</td>\n      <td>72000.0</td>\n      <td>269550.0</td>\n      <td>12001.5</td>\n      <td>225000.0</td>\n      <td>0.025164</td>\n      <td>-20775</td>\n      <td>365243</td>\n      <td>-4388.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3.743750</td>\n      <td>0.166687</td>\n      <td>0.044524</td>\n      <td>-17.580890</td>\n    </tr>\n    <tr>\n      <th>307508</th>\n      <td>456253</td>\n      <td>0</td>\n      <td>153000.0</td>\n      <td>677664.0</td>\n      <td>29979.0</td>\n      <td>585000.0</td>\n      <td>0.005002</td>\n      <td>-14966</td>\n      <td>-7921</td>\n      <td>-6737.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>4.429176</td>\n      <td>0.195941</td>\n      <td>0.044239</td>\n      <td>0.529266</td>\n    </tr>\n    <tr>\n      <th>307509</th>\n      <td>456254</td>\n      <td>0</td>\n      <td>171000.0</td>\n      <td>370107.0</td>\n      <td>20205.0</td>\n      <td>319500.0</td>\n      <td>0.005313</td>\n      <td>-11961</td>\n      <td>-4786</td>\n      <td>-2562.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>2.164368</td>\n      <td>0.118158</td>\n      <td>0.054592</td>\n      <td>0.400134</td>\n    </tr>\n    <tr>\n      <th>307510</th>\n      <td>456255</td>\n      <td>0</td>\n      <td>157500.0</td>\n      <td>675000.0</td>\n      <td>49117.5</td>\n      <td>675000.0</td>\n      <td>0.046220</td>\n      <td>-16856</td>\n      <td>-1262</td>\n      <td>-5128.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>4.285714</td>\n      <td>0.311857</td>\n      <td>0.072767</td>\n      <td>0.074869</td>\n    </tr>\n  </tbody>\n</table>\n<p>307511 rows Ã— 110 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "domain_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(307511, 110)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "domain_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "submit = test_data[['SK_ID_CURR']]\n",
    "submit['TARGET'] = predictions\n",
    "# submit\n",
    "# # Save the submission dataframe\n",
    "submit.to_csv('rf_domain_knowledge_prediction.csv', index = False)"
   ]
  },
  {
   "source": [
    "### Gradient Boosting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Data Shape:  (307511, 104)\n",
      "Testing Data Shape:  (48744, 104)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.793757\ttrain's binary_logloss: 0.552943\tvalid's auc: 0.749536\tvalid's binary_logloss: 0.569006\n",
      "[400]\ttrain's auc: 0.823743\ttrain's binary_logloss: 0.523615\tvalid's auc: 0.749387\tvalid's binary_logloss: 0.551426\n",
      "Early stopping, best iteration is:\n",
      "[355]\ttrain's auc: 0.817969\ttrain's binary_logloss: 0.529324\tvalid's auc: 0.749778\tvalid's binary_logloss: 0.554867\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.793117\ttrain's binary_logloss: 0.553697\tvalid's auc: 0.752181\tvalid's binary_logloss: 0.567972\n",
      "Early stopping, best iteration is:\n",
      "[215]\ttrain's auc: 0.795786\ttrain's binary_logloss: 0.551059\tvalid's auc: 0.752289\tvalid's binary_logloss: 0.56642\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.792203\ttrain's binary_logloss: 0.555149\tvalid's auc: 0.75679\tvalid's binary_logloss: 0.569992\n",
      "Early stopping, best iteration is:\n",
      "[190]\ttrain's auc: 0.790435\ttrain's binary_logloss: 0.556805\tvalid's auc: 0.756814\tvalid's binary_logloss: 0.570967\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.793439\ttrain's binary_logloss: 0.553507\tvalid's auc: 0.7504\tvalid's binary_logloss: 0.568077\n",
      "Early stopping, best iteration is:\n",
      "[224]\ttrain's auc: 0.797645\ttrain's binary_logloss: 0.549475\tvalid's auc: 0.750531\tvalid's binary_logloss: 0.565665\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.792476\ttrain's binary_logloss: 0.554404\tvalid's auc: 0.753406\tvalid's binary_logloss: 0.569046\n",
      "[400]\ttrain's auc: 0.822173\ttrain's binary_logloss: 0.525598\tvalid's auc: 0.753411\tvalid's binary_logloss: 0.551589\n",
      "Early stopping, best iteration is:\n",
      "[329]\ttrain's auc: 0.812218\ttrain's binary_logloss: 0.535414\tvalid's auc: 0.753738\tvalid's binary_logloss: 0.557435\n"
     ]
    }
   ],
   "source": [
    "def gradientboost(features, test_features, encoding = 'ohe', n_folds = 5):\n",
    "    \n",
    "    \"\"\"Train and test a light gradient boosting model using\n",
    "    cross validation. \n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "        features (pd.DataFrame): \n",
    "            dataframe of training features to use \n",
    "            for training a model. Must include the TARGET column.\n",
    "        test_features (pd.DataFrame): \n",
    "            dataframe of testing features to use\n",
    "            for making predictions with the model. \n",
    "        encoding (str, default = 'ohe'): \n",
    "            method for encoding categorical variables. Either 'ohe' for one-hot encoding or 'le' for integer label encoding\n",
    "            n_folds (int, default = 5): number of folds to use for cross validation\n",
    "        \n",
    "    Return\n",
    "    --------\n",
    "        submission (pd.DataFrame): \n",
    "            dataframe with `SK_ID_CURR` and `TARGET` probabilities\n",
    "            predicted by the model.\n",
    "        feature_importances (pd.DataFrame): \n",
    "            dataframe with the feature importances from the model.\n",
    "        valid_metrics (pd.DataFrame): \n",
    "            dataframe with training and validation metrics (ROC AUC) for each fold and overall.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the ids\n",
    "    train_ids = features['SK_ID_CURR']\n",
    "    test_ids = test_features['SK_ID_CURR']\n",
    "    \n",
    "    # Extract the labels for training\n",
    "    labels = features['TARGET']\n",
    "    \n",
    "    # Remove the ids and target\n",
    "    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n",
    "    \n",
    "    \n",
    "    # One Hot Encoding\n",
    "    if encoding == 'ohe':\n",
    "        features = pd.get_dummies(features)\n",
    "        test_features = pd.get_dummies(test_features)\n",
    "        \n",
    "        # Align the dataframes by the columns\n",
    "        features, test_features = features.align(test_features, join = 'inner', axis = 1)\n",
    "        \n",
    "        # No categorical indices to record\n",
    "        cat_indices = 'auto'\n",
    "    \n",
    "    # Integer label encoding\n",
    "    elif encoding == 'le':\n",
    "        \n",
    "        # Create a label encoder\n",
    "        label_encoder = LabelEncoder()\n",
    "        \n",
    "        # List for storing categorical indices\n",
    "        cat_indices = []\n",
    "        \n",
    "        # Iterate through each column\n",
    "        for i, col in enumerate(features):\n",
    "            if features[col].dtype == 'object':\n",
    "                # Map the categorical features to integers\n",
    "                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n",
    "                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n",
    "\n",
    "                # Record the categorical indices\n",
    "                cat_indices.append(i)\n",
    "    \n",
    "    # Catch error if label encoding scheme is not valid\n",
    "    else:\n",
    "        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n",
    "        \n",
    "    print('Training Data Shape: ', features.shape)\n",
    "    print('Testing Data Shape: ', test_features.shape)\n",
    "    \n",
    "    # Extract feature names\n",
    "    feature_names = list(features.columns)\n",
    "    \n",
    "    # Convert to np arrays\n",
    "    features = np.array(features)\n",
    "    test_features = np.array(test_features)\n",
    "    \n",
    "    # Create the kfold object\n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = 50)\n",
    "    \n",
    "    # Empty array for feature importances\n",
    "    feature_importance_values = np.zeros(len(feature_names))\n",
    "    \n",
    "    # Empty array for test predictions\n",
    "    test_predictions = np.zeros(test_features.shape[0])\n",
    "    \n",
    "    # Empty array for out of fold validation predictions\n",
    "    out_of_fold = np.zeros(features.shape[0])\n",
    "    \n",
    "    # Lists for recording validation and training scores\n",
    "    valid_scores = []\n",
    "    train_scores = []\n",
    "    \n",
    "    # Iterate through each fold\n",
    "    for train_indices, valid_indices in k_fold.split(features):\n",
    "        \n",
    "        # Training data for the fold\n",
    "        train_features, train_labels = features[train_indices], labels[train_indices]\n",
    "        # Validation data for the fold\n",
    "        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
    "        \n",
    "        # Create the model\n",
    "        model = lgb.LGBMClassifier(n_estimators=10000, objective = 'binary', \n",
    "                                   class_weight = 'balanced', learning_rate = 0.05, \n",
    "                                   reg_alpha = 0.1, reg_lambda = 0.1, \n",
    "                                   subsample = 0.8, n_jobs = -1, random_state = 50)\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n",
    "                  early_stopping_rounds = 100, verbose = 200)\n",
    "        \n",
    "        # Record the best iteration\n",
    "        best_iteration = model.best_iteration_\n",
    "        \n",
    "        # Record the feature importances\n",
    "        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n",
    "        \n",
    "        # Make predictions\n",
    "        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n",
    "        \n",
    "        # Record the out of fold predictions\n",
    "        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n",
    "        \n",
    "        # Record the best score\n",
    "        valid_score = model.best_score_['valid']['auc']\n",
    "        train_score = model.best_score_['train']['auc']\n",
    "        \n",
    "        valid_scores.append(valid_score)\n",
    "        train_scores.append(train_score)\n",
    "        \n",
    "        # Clean up memory\n",
    "        gc.enable()\n",
    "        del model, train_features, valid_features\n",
    "        gc.collect()\n",
    "        \n",
    "    # Make the submission dataframe\n",
    "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n",
    "    \n",
    "    # Make the feature importance dataframe\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
    "    \n",
    "    # Overall validation score\n",
    "    valid_auc = roc_auc_score(labels, out_of_fold)\n",
    "    \n",
    "    # Add the overall scores to the metrics\n",
    "    valid_scores.append(valid_auc)\n",
    "    train_scores.append(np.mean(train_scores))\n",
    "    \n",
    "    # Needed for creating dataframe of validation scores\n",
    "    fold_names = list(range(n_folds))\n",
    "    fold_names.append('overall')\n",
    "    \n",
    "    # Dataframe of validation scores\n",
    "    metrics = pd.DataFrame({'fold': fold_names,\n",
    "                            'train': train_scores,\n",
    "                            'valid': valid_scores}) \n",
    "    \n",
    "    return submission, feature_importances, metrics\n",
    "submission, fi, metrics = gradientboost(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       SK_ID_CURR    TARGET\n",
       "0          100001  0.268405\n",
       "1          100005  0.428990\n",
       "2          100013  0.123399\n",
       "3          100028  0.201264\n",
       "4          100038  0.566734\n",
       "...           ...       ...\n",
       "48739      456221  0.153647\n",
       "48740      456222  0.296940\n",
       "48741      456223  0.226013\n",
       "48742      456224  0.425601\n",
       "48743      456250  0.594157\n",
       "\n",
       "[48744 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SK_ID_CURR</th>\n      <th>TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100001</td>\n      <td>0.268405</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100005</td>\n      <td>0.428990</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100013</td>\n      <td>0.123399</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100028</td>\n      <td>0.201264</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100038</td>\n      <td>0.566734</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48739</th>\n      <td>456221</td>\n      <td>0.153647</td>\n    </tr>\n    <tr>\n      <th>48740</th>\n      <td>456222</td>\n      <td>0.296940</td>\n    </tr>\n    <tr>\n      <th>48741</th>\n      <td>456223</td>\n      <td>0.226013</td>\n    </tr>\n    <tr>\n      <th>48742</th>\n      <td>456224</td>\n      <td>0.425601</td>\n    </tr>\n    <tr>\n      <th>48743</th>\n      <td>456250</td>\n      <td>0.594157</td>\n    </tr>\n  </tbody>\n</table>\n<p>48744 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('lbg.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Data Shape:  (307511, 108)\n",
      "Testing Data Shape:  (48744, 108)\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.800843\ttrain's binary_logloss: 0.545555\tvalid's auc: 0.758017\tvalid's binary_logloss: 0.562054\n",
      "Early stopping, best iteration is:\n",
      "[237]\ttrain's auc: 0.806928\ttrain's binary_logloss: 0.539431\tvalid's auc: 0.758148\tvalid's binary_logloss: 0.558433\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.799719\ttrain's binary_logloss: 0.546947\tvalid's auc: 0.761082\tvalid's binary_logloss: 0.561529\n",
      "Early stopping, best iteration is:\n",
      "[238]\ttrain's auc: 0.806258\ttrain's binary_logloss: 0.540422\tvalid's auc: 0.761158\tvalid's binary_logloss: 0.557712\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.799303\ttrain's binary_logloss: 0.547742\tvalid's auc: 0.764886\tvalid's binary_logloss: 0.562918\n",
      "Early stopping, best iteration is:\n",
      "[203]\ttrain's auc: 0.799834\ttrain's binary_logloss: 0.547211\tvalid's auc: 0.764918\tvalid's binary_logloss: 0.562613\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.800598\ttrain's binary_logloss: 0.546253\tvalid's auc: 0.760276\tvalid's binary_logloss: 0.560859\n",
      "Early stopping, best iteration is:\n",
      "[254]\ttrain's auc: 0.809874\ttrain's binary_logloss: 0.537001\tvalid's auc: 0.761\tvalid's binary_logloss: 0.555246\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttrain's auc: 0.800033\ttrain's binary_logloss: 0.546766\tvalid's auc: 0.761671\tvalid's binary_logloss: 0.562475\n",
      "[400]\ttrain's auc: 0.829466\ttrain's binary_logloss: 0.517195\tvalid's auc: 0.761865\tvalid's binary_logloss: 0.544567\n",
      "Early stopping, best iteration is:\n",
      "[329]\ttrain's auc: 0.820058\ttrain's binary_logloss: 0.526833\tvalid's auc: 0.762243\tvalid's binary_logloss: 0.550316\n"
     ]
    }
   ],
   "source": [
    "submission_domain, fi_domain, metrics_domain = gradientboost(domain_train, domain_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_domain\n",
    "submission_domain.to_csv('lgb_domain_feature.csv', index = False)"
   ]
  },
  {
   "source": [
    "## Problem 5: Final model selection\n",
    "Ultimately, choose a model that says it's good and submit the estimated results to Kaggle to see your score. Please describe what kind of idea you adopted and what the score was"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Public Score Result:\n",
    "<li> Previous Submission using Logarit Regression: 0.68426 </li>\n",
    "<li> Random Forest: 0.42773 </li>\n",
    "<li> Random Forest with Domain Knowledge: 0.69985 </li>\n",
    "<li> Gradient Boost: 0.74453</li>\n",
    "<li> Gradient Boost with Domain Knowledge: 0.76053</li>\n",
    "\n",
    "### Private Score Result:\n",
    "<li> Previous Submission using Logarit Regression: 0.68426 </li>\n",
    "<li> Random Forest: 0.43378 </li>\n",
    "<li> Random Forest with Domain Knowledge: 0.70319 </li>\n",
    "<li> Gradient Boost: 0.74611 </li>\n",
    "<li> Gradient Boost with Domain Knowledge: 0.76074</li>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "For all the model and paramter i have tried, Gradient Boosting is the best one. With 0.75238 in public and 0.75294 in private. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}